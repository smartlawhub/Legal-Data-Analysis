import requests
import regex as re
from bs4 import BeautifulSoup
import pandas as pd

url = "https://recherche.conseil-constitutionnel.fr/?expert=2&filtres1%5B0%5D=sous_type_decision:QPC"  # First, we get the dataset, which in this case is
cassdf=pd.DataFrame([],columns=["Numéro-décision","titre","type","date","visa"]) #création du dataframe dès le début

def construct_sublist(a): #a est un paramètre de la fonction contruite, il rpz la décision
    sublist = 5*[""] #la sublist ne peut contenir que 5 éléments : numéro décision, titre, type, date, visa. Elle est vide au début
    solution = a.find("span", class_="type").get_text() #on extrait le texte lié à la balise "span de class type" de la décision a
    solution = re.split("\[|\]", solution)[1] #grâce à une regex, on retire les crochets, on garde le deuxième élèment du tableau qui est la solution
    date = a.find("span", class_="date").get_text() #on extrait le texte lié à la balise "span de class date" de la décision a
    sujetQPC = a.find("a").get_text() #on extrait le texte lié à la balise "a" de la décision a
    tab = re.split('\[|\]| QPC|- ', sujetQPC) # "\" enlève le caractère spécial, "|" ou, on split la balise "a" à chaque fois qu'il rencontre un de ces élements et le met dans le tableau "tab"
    sublist[0]=tab[1] #a la position zero on a tab 1, numéro de décision
    sublist[1]=tab[4] #a la position 2 on a tab 4, rejouter sujet de la décision, entre crochet
    sublist[2]=date #rajouter la date
    sublist[3]=solution #rajouter la solution
    return sublist
i=0 # i est le compteur qui augmentera à chaque texte ligne 49
for x in range (92) : #boucle 92 fois pour les 92 pages
    webpage = requests.get(url)  # We connect on the first page that lists 10 decisions
    soup = BeautifulSoup(webpage.content, "html.parser")  # We get the html of that page
    aas = soup.find_all("article", class_="type-decision") # And we find the elements representing these decisions themselves, tableau de décision de la page, cahqeu case du tableau est une décision avec son contenu html
    for a in aas : # We start a second loop, going now decision by decision, using the elements we just found, on loop sur les 10a de aas (a= chaque décision une par une)
        href = a.find("a").get("href") # Each of that element, in the attribute href, has the url to the decision itself, a.find = on cherche dans la décision (a) la balise "a" et dans cette balise on extrait le href qui est l'url de redirction de la décision
        # Looping through that list, we create a sublist in which we add info about each case, starting with the url
        sublist=construct_sublist(a) #sublist avec 4 éléments a ce moment. Subliste est la liste des données extraites pour chaque décision, avec une sublist par décision
        webpage2=requests.get(href)  # we connect on the page of the décision en fonction du href (URL de redirection de chaque décision) récupéré
        soup2=BeautifulSoup(webpage2.content, "html.parser")  # We get the html of that page

        aas2=[]  #tableau de textes de visa
        if (x<44):
            aas2=soup2.find_all("div",class_="wrapper-content")[0].find_all("ul")[0].find_all("li") #jusque la page 44,on récupère tous les "li" (chaque visa) dans le premier "ul" (tous les visas), du premier wrapper content, aas2 est un tableau qui contient tous les textes du visa listés sous forma html
        else:
            temp=soup2.find_all("div",class_="wrapper-content")[0].find_all("p") # on récupère toute les balises paragraphe du div wrapper content, qu'on stock dans la variable temp (tableau de balise p)
            for elt in temp: #on parcours le tableau temp. Deux choses ne nous intéressent pas, le paragraphe introductif et le CONSEIL CONSTIUTIONNEL
                if re.match("^Vu le règlement du 4 février",elt.get_text()): #que l'élement match la regex. a partir de cette ligne, on ne récupère plus les textes. Le chapeau est un caractère spé qui implique que commence par vu
                    break #on quitte le for et on passe aux deuxième for
                elif temp.index(elt)==0 or temp.index(elt)==1: # si premier ou deuxième élément on continue, on les next
                    continue
                else:
                    aas2.append(elt) #si aucun des 2 précédent, il append
        for obj in aas2: #on parcours les textes dans aas2
            sublist[4]=re.split('\xa0;',obj.get_text())[0] # pour chaque texte on le nettoie, et on l'ajoute à la position 4 de la sublist, 5eme élément
            cassdf.loc[i]=sublist #.loc est une fonction qui ajoute la donnée à la location index "i" dans le data frame
            i+=1 # pour mettre une ligne un visa, on augmente i à chaque fois qu'on a ajouté un texte.
    if (x!=91):  # si x=91 on ne boucle pas la partie suivante (car pas de page suivante à la dernière page)
        li=soup.find_all("li", class_="pager__item pager__item--next")#liste simple, avec deux li
        dom="https://recherche.conseil-constitutionnel.fr/"
        truc=li[0].find("a").get("href")#récup&ration href du tout premier élément du tableau
        rest=re.split('\?',truc)#en regex '?' est une caractère spéciale donc mettre backslash avant pour avoir le caractere simple
        #split divise une string donnée selon un caractère en l'occurence le point d'interrogation
        url=dom+'?'+rest[1]#construction url =>nom de domaine+?+queryparams

cassdf.to_csv('cassdf.csv')

import matplotlib.pyplot as plt
import pandas as pd
import locale
locale.setlocale(locale.LC_ALL, "fr_FR") # On change la locale pour qu'il puisse comprendre que les dates sont au format fr


df = pd.read_csv("cassdf3.csv", header="infer")
df.index = pd.to_datetime(df["Date"], format="%d %B %Y") # On réindexe à l'aide de la date transformée au format datetime
df.Date = pd.to_datetime(df["Date"], format="%d %B %Y")

# pour compter et plotter tous les outcomes par periode d'un an
df.resample("1Y").Outcome.value_counts().unstack().plot() # Ce réindexing permet du "resampling", qui prend comme argument une période
# On utilise le value_count() pour obtenir le nombre de visa par période donnée; une fois "unstack" (pour avoir index+colonnes), on peut le plot.
plt.title('Conformité / an')
plt.grid(True)
plt.legend(bbox_to_anchor=(1.04, 1), loc="upper left")
plt.show()

# pour compter et plotter les differents codes par rapport au code de la santé publique par periode d'un an
X = ["le code de la santé publique","le code civil"]
grouper = df.loc[df.VISA.isin(X)].groupby([pd.Grouper(key='Date', freq='Y'),  "VISA"])
ax2 = grouper["VISA"].size().unstack().plot(kind="bar")
ax2.set_title('Nombre de VISA/ an')
ax2.xaxis.set_ticklabels([pd.to_datetime(x).year for x in df.loc[df.VISA == "le code de la santé publique"].resample("1Y").size().index.values.tolist()])
plt.show()

X = ["le code de la santé publique","le code pénal"]
grouper = df.loc[df.VISA.isin(X)].groupby([pd.Grouper(key='Date', freq='Y'),  "VISA"])
ax2 = grouper["VISA"].size().unstack().plot(kind="bar")
ax2.set_title('Nombre de VISA/ an')
ax2.xaxis.set_ticklabels([pd.to_datetime(x).year for x in df.loc[df.VISA == "le code de la santé publique"].resample("1Y").size().index.values.tolist()])
plt.show()

X = ["le code de la santé publique","le code de justice administrative"]
grouper = df.loc[df.VISA.isin(X)].groupby([pd.Grouper(key='Date', freq='Y'),  "VISA"])
ax2 = grouper["VISA"].size().unstack().plot(kind="bar")
ax2.set_title('Nombre de VISA/ an')
ax2.xaxis.set_ticklabels([pd.to_datetime(x).year for x in df.loc[df.VISA == "le code de la santé publique"].resample("1Y").size().index.values.tolist()])
plt.show()

X = ["le code de la santé publique","le code monétaire et financier"]
grouper = df.loc[df.VISA.isin(X)].groupby([pd.Grouper(key='Date', freq='Y'),  "VISA"])
ax2 = grouper["VISA"].size().unstack().plot(kind="bar")
ax2.set_title('Nombre de VISA All')
ax2.xaxis.set_ticklabels([pd.to_datetime(x).year for x in df.loc[df.VISA == "le code de la santé publique"].resample("1Y").size().index.values.tolist()])
plt.show()

X = ["le code de la santé publique","le code général des impôts"]
grouper = df.loc[df.VISA.isin(X)].groupby([pd.Grouper(key='Date', freq='Y'),  "VISA"])
ax2 = grouper["VISA"].size().unstack().plot(kind="bar")
ax2.set_title('Nombre de VISA All')
ax2.xaxis.set_ticklabels([pd.to_datetime(x).year for x in df.loc[df.VISA == "le code de la santé publique"].resample("1Y").size().index.values.tolist()])
plt.show()

X = ["le code de la santé publique","le code de procédure pénale"]
grouper = df.loc[df.VISA.isin(X)].groupby([pd.Grouper(key='Date', freq='Y'),  "VISA"])
ax2 = grouper["VISA"].size().unstack().plot(kind="bar")
ax2.set_title('Nombre de VISA All')
ax2.xaxis.set_ticklabels([pd.to_datetime(x).year for x in df.loc[df.VISA == "le code de la santé publique"].resample("1Y").size().index.values.tolist()])
plt.show()

X = ["le code de la santé publique","le code de l'environnement"]
grouper = df.loc[df.VISA.isin(X)].groupby([pd.Grouper(key='Date', freq='Y'),  "VISA"])
ax2 = grouper["VISA"].size().unstack().plot(kind="bar")
ax2.set_title('Nombre de VISA All')
ax2.xaxis.set_ticklabels([pd.to_datetime(x).year for x in df.loc[df.VISA == "le code de la santé publique"].resample("1Y").size().index.values.tolist()])
plt.show()

X = ["le code de la santé publique","le code de la sécurité sociale"]
grouper = df.loc[df.VISA.isin(X)].groupby([pd.Grouper(key='Date', freq='Y'),  "VISA"])
ax2 = grouper["VISA"].size().unstack().plot(kind="bar")
ax2.set_title('Nombre de VISA All')
ax2.xaxis.set_ticklabels([pd.to_datetime(x).year for x in df.loc[df.VISA == "le code de la santé publique"].resample("1Y").size().index.values.tolist()])
plt.show()

X = ["le code de la santé publique","le code du travail"]
grouper = df.loc[df.VISA.isin(X)].groupby([pd.Grouper(key='Date', freq='Y'),  "VISA"])
ax2 = grouper["VISA"].size().unstack().plot(kind="bar")
ax2.set_title('Nombre de VISA All')
ax2.xaxis.set_ticklabels([pd.to_datetime(x).year for x in df.loc[df.VISA == "le code de la santé publique"].resample("1Y").size().index.values.tolist()])
plt.show()
