{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tx8B-Txm36DB"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import spacy\n",
        "import regex as re\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def extract_judge_name(decision_url): # used to extract judge names\n",
        "    response = requests.get(decision_url)\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        blockquote_tag = soup.find('blockquote').text.strip()\n",
        "        match = re.search(r'par le Conseil constitutionnel.*?([A-Z]{4,})', blockquote_tag, re.DOTALL) # We searched every word in the blockquote_tag that contained the following caracteristics: *?([A-Z]{4,}) and which was located right after \"par le Conseil constitutionnel\"\n",
        "        if match:\n",
        "            judge_name = match.group(1)\n",
        "            if judge_name == \"DEBR\":\n",
        "                judge_name += \"É\" # the code didn't take into account the French accents, so we had to add this code line\n",
        "            return judge_name\n",
        "        else:\n",
        "            return \"Unidentified\"\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "url_prefix = \"https://www.conseil-constitutionnel.fr/les-decisions?cc-page=\"\n",
        "main_list = [] # we create an empty main list, in which we will then add our sublists\n",
        "\n",
        "for x in range(1, 343): # There are 342 pages but we have to write down 343 so that the last page is taken into account\n",
        "    webpage = requests.get(url_prefix + str(x)) # we connect on the page containing the URLs of the decisions, page by page (20 results per page by default)\n",
        "    soup = BeautifulSoup(webpage.content, \"html.parser\") # we ask for the html of each page\n",
        "    aas = soup.find_all(\"div\", class_=\"views-row\") # we find the elements representing each decision on the said page\n",
        "\n",
        "    for a in aas: # second loop to scrap data decision by decision on the said page\n",
        "        href = a.find(\"a\").get(\"href\") # we find the URL of each decision\n",
        "        sublist = [href] # we create a sublist to then add to the mainlist the necessary information for each case\n",
        "        title = a.find(\"div\", class_=\"title\").text.split(\" \") # used to extract the title and split it\n",
        "        year = None\n",
        "        type_decision = None\n",
        "\n",
        "        for word in title:\n",
        "            year_match = re.search(r'\\b(\\d{4})\\b', word) # we look for the year of each decision in the title using a regex\n",
        "            if year_match:\n",
        "                year = year_match.group(1)\n",
        "\n",
        "            type_decision_match = re.search(r'\\b([A-Z]{2,})\\b', word) # we look for the type of decision of each decision in the title using a regex\n",
        "            if type_decision_match:\n",
        "                type_decision = type_decision_match.group(1)\n",
        "\n",
        "        if year:\n",
        "            sublist.append(year)\n",
        "        else:\n",
        "            sublist.append(\"Year unidentified\")\n",
        "\n",
        "        if type_decision:\n",
        "            sublist.append(type_decision)\n",
        "        else:\n",
        "            sublist.append(\"L\") #as we were looking for types of decisions containing at least 2 capital letters, we couldn't find the \"L\" type of decisions. We thus added this line\n",
        "\n",
        "        try:\n",
        "            solution = a.find(\"div\", class_=\"field field--name-field-solution-normalisee field--type-string field--label-hidden field__item\").text # we look for the solution of each decision in the said page\n",
        "        except Exception as e:\n",
        "            solution=\"introuvable\"\n",
        "        sublist.append(solution)\n",
        "\n",
        "        detail_webpage = requests.get(\"https://www.conseil-constitutionnel.fr\" + href) # we connect to the decision page itself\n",
        "        detail_soup = BeautifulSoup(detail_webpage.content, \"html.parser\") # we ask for the html of the decision's page\n",
        "        detail_div = detail_soup.find(\"div\", class_=\"clearfix text-formatted field field--name-field-contenu-original field--type-text-long field--label-hidden field__item\") # we look for our answer in a specific element of the decision's html code\n",
        "\n",
        "        if detail_div:\n",
        "            text = detail_div.getText()\n",
        "            debut = re.search(\"LE CONSEIL CONSTITUTIONNEL A ÉTÉ SAISI\", text)\n",
        "            length = len(text) # used to extract the calculate the length of each decision\n",
        "            sublist.append(length) # we put our lengths in our sublist\n",
        "\n",
        "\n",
        "        decision_url = \"https://www.conseil-constitutionnel.fr\" + href # For this section we had to add several lines to account for the inconsistensies (especially decisisions in which the name of the judge wasn't written and the code picked upcode lines to take into a \"ECLI\")\n",
        "        judge_name = extract_judge_name(decision_url)\n",
        "        if judge_name in [\"JUPP\", \"ORGA\"]: #still don't know why FABIUS wasn't being picked\n",
        "            judge_name = \"FABIUS\"\n",
        "        elif judge_name == \"AMELLER\":  #The regex was picking up AMELLER instead or GUÉNA because of the 'accent'\n",
        "            judge_name = \"GUÉNA\"\n",
        "        elif judge_name == \"ABADIE\":  # same reason\n",
        "            judge_name = \"GUÉNA\"\n",
        "        elif x == 173 and judge_name == \"ECLI\":\n",
        "            judge_name = \"MAZEAUD\"\n",
        "        elif x == 175 and judge_name == \"ECLI\":\n",
        "            judge_name = \"MAZEAUD\"\n",
        "        elif x == 195 and judge_name == \"ECLI\": #same reason again\n",
        "            judge_name = \"GUÉNA\"\n",
        "        elif x in [226, 227, 228] and judge_name == \"ECLI\":\n",
        "            judge_name = \"Unidentified\"\n",
        "        elif x == 269 and judge_name == \"ECLI\":\n",
        "            judge_name = \"Unidentified\"\n",
        "        elif x == 271 and judge_name == \"ECLI\":\n",
        "            judge_name = \"Unidentified\"\n",
        "        elif x == 272 and judge_name == \"ECLI\":\n",
        "            judge_name = \"Unidentified\"\n",
        "        elif x in [273, 274, 275, 277, 279, 280] and judge_name == \"ECLI\":\n",
        "            judge_name = \"Unidentified\"\n",
        "        elif x in [279, 280] and judge_name == \"JOXE\":\n",
        "            judge_name = \"BADINTER\"\n",
        "        elif x == 321 and judge_name == \"ECLI\":\n",
        "            judge_name = \"PALEWSKI\"\n",
        "        elif 308 <= x <= 314 and judge_name == \"ECLI\":\n",
        "            judge_name = \"Unidentified\"\n",
        "        elif 326 <= x <= 335 and judge_name == \"ECLI\":\n",
        "            judge_name = \"Unidentified\"\n",
        "        elif 293 <= x <= 305 and judge_name == \"ECLI\":\n",
        "            judge_name = \"Unidentified\"\n",
        "        elif 280 <= x <= 288 and judge_name == \"ECLI\":\n",
        "            judge_name = \"Unidentified\"\n",
        "        elif judge_name == \"FRET\": # Misspelled last name\n",
        "            judge_name = \"FREY\"\n",
        "        elif judge_name == \"GUENA\": # The site is very inconsistent in the way they write SURNAMES\n",
        "            judge_name = \"GUÉNA\"\n",
        "        sublist.append(judge_name) # we put the judges' names in our sublist\n",
        "\n",
        "        main_list.append(sublist)# we put all the sublists into our main list in order to be able to create a dataframe\n",
        "\n",
        "\n",
        "constitdf = pd.DataFrame(main_list, columns=[\"URL\", \"Année\", \"Type de décision\", \"Solution\", \"Length\", \"Juge\"]) # we create a dataframe\n",
        "constitdf.to_csv(\"constitdf.csv\", encoding=\"utf8\") # we save the data to CSV\n",
        "\n",
        "\n",
        "\n",
        "#1st graph: mean decisions' length per year: linear graph\n",
        "\n",
        "# Convert 'Length' column to numeric\n",
        "constitdf['Length'] = pd.to_numeric(constitdf['Length'], errors='coerce')\n",
        "\n",
        "# Calculate mean decisions' length per year\n",
        "mean_length_per_year = constitdf.groupby('Année')['Length'].mean()\n",
        "\n",
        "# Plot linear graph for mean decisions' length per year\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(mean_length_per_year.index, mean_length_per_year, marker='o', color='green', linestyle='-')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Average length of decisions')\n",
        "plt.title('Average length of decisions per year')\n",
        "plt.grid(True)\n",
        "plt.xlim(min(mean_length_per_year.index), max(mean_length_per_year.index))  # We set the x-axis limits\n",
        "plt.xticks(rotation='vertical')  # we rotate the x-axis labels vertically\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#2nd graph: number of decisions taken by each President of the Conseil Constitutionnel: histogram graph\n",
        "\n",
        "# Group data by judge and count the number of decisions for each President\n",
        "judge_counts = constitdf['Juge'].value_counts()\n",
        "\n",
        "# Plot histogram\n",
        "plt.figure(figsize=(15, 6))\n",
        "judge_counts.plot(kind='bar')\n",
        "plt.title('Number of decisions issued by each presiding judge')\n",
        "plt.xlabel('Name of the presiding judges')\n",
        "plt.ylabel('Number of decisions')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "#3rd graph graphique: number of decisions per year : linear graph\n",
        "\n",
        "# Count the number of decisions per year\n",
        "decisions_per_year = constitdf['Année'].value_counts().sort_index()\n",
        "\n",
        "# Plot linear graph for number of decisions per year\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(decisions_per_year.index, decisions_per_year, marker='o', color='red', linestyle='-')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of decisions')\n",
        "plt.title('Number of decisions per year')\n",
        "plt.xticks(rotation=45) # We rotate the x-axis labels for better readability\n",
        "plt.grid(True) # Add gridlines for better readability\n",
        "plt.xlim(min(decisions_per_year.index), max(decisions_per_year.index))  # Set x-axis limits\n",
        "plt.xticks(rotation='vertical')  # Rotate x-axis labels vertically\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#4th graph: number of decision for each type of decision since 1958: histogram graph\n",
        "\n",
        "# Count the number of decisions for each type of capitalized word:\n",
        "type_decision_counts = constitdf['Type de décision'].value_counts()\n",
        "\n",
        "# Plot bar graph\n",
        "plt.figure(figsize=(15, 6))\n",
        "type_decision_counts.plot(kind='bar', color='pink')\n",
        "plt.xlabel('Type of decisions')\n",
        "plt.ylabel('Number of decisions')\n",
        "plt.title('Number of decisions by type since 1958')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ]
}